{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/igumiao/nlp_G60/blob/xiaohong/Group60__COMP90042_Project_2025.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32yCsRUo8H33"
      },
      "source": [
        "# 2025 COMP90042 Project\n",
        "*Make sure you change the file name with your group id.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XCybYoGz8YWQ"
      },
      "source": [
        "# Readme\n",
        "*If there is something to be noted for the marker, please mention here.*\n",
        "\n",
        "*If you are planning to implement a program with Object Oriented Programming style, please put those the bottom of this ipynb file*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6po98qVA8bJD"
      },
      "source": [
        "# 1.DataSet Processing\n",
        "(You can add as many code blocks and text blocks as you need. However, YOU SHOULD NOT MODIFY the section title)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\10762\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\10762\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     C:\\Users\\10762\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using GPU: NVIDIA GeForce RTX 3060 Laptop GPU\n",
            "Loading ./data\\train-claims.json...\n",
            "Successfully loaded 1228 items.\n",
            "Loading ./data\\dev-claims.json...\n",
            "Successfully loaded 154 items.\n",
            "Loading ./data\\test-claims-unlabelled.json...\n",
            "Successfully loaded 153 items.\n",
            "Loading ./data\\evidence.json...\n",
            "Successfully loaded 1208827 items.\n",
            "\n",
            "=== Sample Data Structure ===\n",
            "Sample claim ID: claim-1937\n",
            "{\n",
            "  \"claim_text\": \"Not only is there no scientific evidence that CO2 is a pollutant, higher CO2 concentrations actually help ecosystems support more plant and animal life.\",\n",
            "  \"claim_label\": \"DISPUTED\",\n",
            "  \"evidences\": [\n",
            "    \"evidence-442946\",\n",
            "    \"evidence-1194317\",\n",
            "    \"evidence-12171\"\n",
            "  ]\n",
            "}\n",
            "\n",
            "Sample evidence ID: evidence-0\n",
            "Evidence text: John Bennet Lawes, English entrepreneur and agricultural scientist\n",
            "\n",
            "=== Basic Analysis of Training Claims Dataset ===\n",
            "Number of items: 1228\n",
            "\n",
            "Claim_text Length Statistics (in words):\n",
            "  Average length: 20.10\n",
            "  Maximum length: 67\n",
            "  Minimum length: 4\n",
            "\n",
            "=== Basic Analysis of Development Claims Dataset ===\n",
            "Number of items: 154\n",
            "\n",
            "Claim_text Length Statistics (in words):\n",
            "  Average length: 21.08\n",
            "  Maximum length: 65\n",
            "  Minimum length: 4\n",
            "\n",
            "=== Basic Analysis of Test Claims Dataset ===\n",
            "Number of items: 153\n",
            "\n",
            "Claim_text Length Statistics (in words):\n",
            "  Average length: 20.04\n",
            "  Maximum length: 53\n",
            "  Minimum length: 4\n",
            "\n",
            "=== Basic Analysis of Evidence (Sample) Dataset ===\n",
            "Number of items: 1000\n",
            "\n",
            "Evidence text Length Statistics (in words):\n",
            "  Average length: 19.34\n",
            "  Maximum length: 71\n",
            "  Minimum length: 2\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Preprocessing Examples ===\n",
            "Original claim: Not only is there no scientific evidence that CO2 is a pollutant, higher CO2 concentrations actually help ecosystems support more plant and animal life.\n",
            "Basic preprocessing: not only is there no scientific evidence that co2 is a pollutant higher co2 concentrations actually help ecosystems support more plant and animal life\n",
            "With stopword removal: scientific evidence co2 pollutant higher co2 concentrations actually help ecosystems support plant animal life\n",
            "With lemmatization: not only is there no scientific evidence that co2 is a pollutant higher co2 concentration actually help ecosystem support more plant and animal life\n",
            "With stemming: not onli is there no scientif evid that co2 is a pollut higher co2 concentr actual help ecosystem support more plant and anim life\n",
            "\n",
            "Original evidence: John Bennet Lawes, English entrepreneur and agricultural scientist\n",
            "Basic preprocessing: john bennet lawes english entrepreneur and agricultural scientist\n",
            "With stopword removal: john bennet lawes english entrepreneur agricultural scientist\n",
            "\n",
            "Data processing complete!\n"
          ]
        }
      ],
      "source": [
        "# 1. DataSet Processing\n",
        "\n",
        "# Import necessary libraries\n",
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
        "from collections import Counter\n",
        "import time\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Download NLTK resources\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "# --- Configuration ---\n",
        "DRIVE_DATA_PATH = './data'  # Path to the data directory\n",
        "\n",
        "# Set device to GPU if available, otherwise CPU\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(\"Using GPU:\", torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"Using CPU\")\n",
        "\n",
        "# File paths\n",
        "TRAIN_CLAIMS_PATH = os.path.join(DRIVE_DATA_PATH, 'train-claims.json')\n",
        "DEV_CLAIMS_PATH = os.path.join(DRIVE_DATA_PATH, 'dev-claims.json')\n",
        "TEST_CLAIMS_PATH = os.path.join(DRIVE_DATA_PATH, 'test-claims-unlabelled.json')\n",
        "EVIDENCE_PATH = os.path.join(DRIVE_DATA_PATH, 'evidence.json')\n",
        "DEV_PREDICTIONS_PATH = os.path.join(DRIVE_DATA_PATH, 'dev-claims-predictions.json')\n",
        "TEST_PREDICTIONS_PATH = os.path.join(DRIVE_DATA_PATH, 'test-claims-predictions.json')\n",
        "EVAL_SCRIPT_PATH = os.path.join('eval.py')\n",
        "\n",
        "# --- Helper Functions ---\n",
        "def load_json(filepath):\n",
        "    \"\"\"Loads JSON data from a file.\"\"\"\n",
        "    print(f\"Loading {filepath}...\")\n",
        "    try:\n",
        "        with open(filepath, 'r', encoding='utf-8') as f:\n",
        "            data = json.load(f)\n",
        "        print(f\"Successfully loaded {len(data)} items.\")\n",
        "        return data\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: File not found at {filepath}\")\n",
        "        return None\n",
        "    except json.JSONDecodeError as e:\n",
        "        print(f\"Error: Could not decode JSON from {filepath}. Error: {e}\")\n",
        "        return None\n",
        "\n",
        "def preprocess_text(text, remove_stop_words=False, lemmatize=False, stem=False):\n",
        "    \"\"\"\n",
        "    Preprocess text with multiple options:\n",
        "    - Lowercase\n",
        "    - Remove special characters\n",
        "    - Optional: Remove stopwords\n",
        "    - Optional: Lemmatization\n",
        "    - Optional: Stemming\n",
        "    \"\"\"\n",
        "    # Convert to lowercase\n",
        "    text = text.lower()\n",
        "    \n",
        "    # Remove special characters and extra spaces\n",
        "    text = re.sub(r'[^\\w\\s]', ' ', text)\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    \n",
        "    # Tokenize the text\n",
        "    tokens = word_tokenize(text)\n",
        "    \n",
        "    # Remove stopwords if requested\n",
        "    if remove_stop_words:\n",
        "        stop_words = set(stopwords.words('english'))\n",
        "        tokens = [word for word in tokens if word not in stop_words]\n",
        "    \n",
        "    # Apply lemmatization if requested\n",
        "    if lemmatize:\n",
        "        lemmatizer = WordNetLemmatizer()\n",
        "        tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
        "    \n",
        "    # Apply stemming if requested\n",
        "    if stem:\n",
        "        stemmer = PorterStemmer()\n",
        "        tokens = [stemmer.stem(word) for word in tokens]\n",
        "    \n",
        "    # Join the tokens back to a string\n",
        "    processed_text = ' '.join(tokens)\n",
        "    \n",
        "    return processed_text\n",
        "\n",
        "def basic_dataset_analysis(data_dict, name):\n",
        "    \"\"\"Basic analysis of a dataset (claims or evidence).\"\"\"\n",
        "    print(f\"\\n=== Basic Analysis of {name} Dataset ===\")\n",
        "    print(f\"Number of items: {len(data_dict)}\")\n",
        "    \n",
        "    # For claims, check label distribution\n",
        "    if name == 'Claims' and 'claim_label' in next(iter(data_dict.values())):\n",
        "        labels = [item.get('claim_label') for item in data_dict.values() if 'claim_label' in item]\n",
        "        label_counts = Counter(labels)\n",
        "        print(\"\\nLabel Distribution:\")\n",
        "        for label, count in label_counts.items():\n",
        "            print(f\"  {label}: {count} ({count/len(labels)*100:.2f}%)\")\n",
        "    \n",
        "    # Check text lengths\n",
        "    if 'claim_text' in next(iter(data_dict.values()), {}):\n",
        "        # For claims\n",
        "        text_field = 'claim_text'\n",
        "        text_lengths = [len(item[text_field].split()) for item in data_dict.values()]\n",
        "    else:\n",
        "        # For evidence\n",
        "        text_lengths = [len(text.split()) for i, text in enumerate(data_dict.values()) if i < 1000]\n",
        "        text_field = 'evidence text'\n",
        "    \n",
        "    print(f\"\\n{text_field.capitalize()} Length Statistics (in words):\")\n",
        "    print(f\"  Average length: {sum(text_lengths)/len(text_lengths):.2f}\")\n",
        "    print(f\"  Maximum length: {max(text_lengths)}\")\n",
        "    print(f\"  Minimum length: {min(text_lengths)}\")\n",
        "    \n",
        "    return text_lengths\n",
        "\n",
        "# --- 1. Load and Explore Datasets ---\n",
        "train_claims = load_json(TRAIN_CLAIMS_PATH)\n",
        "dev_claims = load_json(DEV_CLAIMS_PATH)\n",
        "test_claims = load_json(TEST_CLAIMS_PATH)\n",
        "evidence = load_json(EVIDENCE_PATH)\n",
        "\n",
        "# Print a sample claim to understand structure\n",
        "print(\"\\n=== Sample Data Structure ===\")\n",
        "sample_claim_id = next(iter(train_claims))\n",
        "print(f\"Sample claim ID: {sample_claim_id}\")\n",
        "print(json.dumps(train_claims[sample_claim_id], indent=2))\n",
        "\n",
        "# Print a sample evidence\n",
        "sample_evidence_id = next(iter(evidence))\n",
        "print(f\"\\nSample evidence ID: {sample_evidence_id}\")\n",
        "print(f\"Evidence text: {evidence[sample_evidence_id]}\")\n",
        "\n",
        "# --- 2. Basic Dataset Analysis ---\n",
        "train_lengths = basic_dataset_analysis(train_claims, \"Training Claims\")\n",
        "dev_lengths = basic_dataset_analysis(dev_claims, \"Development Claims\")\n",
        "test_lengths = basic_dataset_analysis(test_claims, \"Test Claims\")\n",
        "\n",
        "# Sample evidence for analysis (avoid analyzing all 1.2M items)\n",
        "sample_evidence = {k: evidence[k] for k in list(evidence.keys())[:1000]}\n",
        "evidence_lengths = basic_dataset_analysis(sample_evidence, \"Evidence (Sample)\")\n",
        "\n",
        "# --- 3. Create a simple visualization ---\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.hist(train_lengths, bins=30, alpha=0.5, label='Claims')\n",
        "plt.hist(evidence_lengths, bins=30, alpha=0.5, label='Evidence')\n",
        "plt.xlabel('Word Count')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Distribution of Text Lengths: Claims vs Evidence')\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.savefig('text_length_distribution.png')\n",
        "plt.show()\n",
        "\n",
        "# --- 4. Preprocessing Examples ---\n",
        "print(\"\\n=== Preprocessing Examples ===\")\n",
        "\n",
        "# Sample a claim\n",
        "sample_claim = train_claims[sample_claim_id]['claim_text']\n",
        "print(f\"Original claim: {sample_claim}\")\n",
        "print(f\"Basic preprocessing: {preprocess_text(sample_claim)}\")\n",
        "print(f\"With stopword removal: {preprocess_text(sample_claim, remove_stop_words=True)}\")\n",
        "print(f\"With lemmatization: {preprocess_text(sample_claim, lemmatize=True)}\")\n",
        "print(f\"With stemming: {preprocess_text(sample_claim, stem=True)}\")\n",
        "\n",
        "# Sample an evidence\n",
        "sample_evidence_text = evidence[sample_evidence_id]\n",
        "print(f\"\\nOriginal evidence: {sample_evidence_text}\")\n",
        "print(f\"Basic preprocessing: {preprocess_text(sample_evidence_text)}\")\n",
        "print(f\"With stopword removal: {preprocess_text(sample_evidence_text, remove_stop_words=True)}\")\n",
        "\n",
        "print(\"\\nData processing complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1FA2ao2l8hOg"
      },
      "source": [
        "# 2. Model Implementation\n",
        "(You can add as many code blocks and text blocks as you need. However, YOU SHOULD NOT MODIFY the section title)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### TFIDF Retriever"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "QIEqDDT78q39"
      },
      "outputs": [],
      "source": [
        "# Define the TF-IDF Evidence Retriever class (simplified)\n",
        "class TfidfEvidenceRetriever:\n",
        "    \"\"\"\n",
        "    TF-IDF based evidence retriever that uses cosine similarity to find \n",
        "    relevant evidence passages for a given claim.\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, \n",
        "                 max_features=10000, \n",
        "                 ngram_range=(1, 2), \n",
        "                 top_k=3,\n",
        "                 lemmatize=False,\n",
        "                 stem=False):\n",
        "        \"\"\"\n",
        "        Initialize the TF-IDF evidence retriever.\n",
        "        \n",
        "        Args:\n",
        "            max_features: Maximum number of features (vocabulary size)\n",
        "            ngram_range: Range of n-grams to include (e.g., (1, 2) for unigrams and bigrams)\n",
        "            top_k: Number of evidence passages to retrieve\n",
        "            lemmatize: Whether to apply lemmatization in preprocessing\n",
        "            stem: Whether to apply stemming in preprocessing\n",
        "        \"\"\"\n",
        "        self.max_features = max_features\n",
        "        self.ngram_range = ngram_range\n",
        "        self.top_k = top_k\n",
        "        \n",
        "        # Preprocessing options\n",
        "        self.lemmatize = lemmatize\n",
        "        self.stem = stem\n",
        "        \n",
        "        # These will be initialized in the fit method\n",
        "        self.vectorizer = None\n",
        "        self.evidence_ids = None\n",
        "        self.evidence_vectors = None\n",
        "        \n",
        "    def fit(self, evidence_data):\n",
        "        \"\"\"\n",
        "        Fit the TF-IDF vectorizer on the evidence data and transform\n",
        "        all evidence passages to TF-IDF vectors.\n",
        "        \n",
        "        Args:\n",
        "            evidence_data: Dictionary of evidence passages {evidence_id: text}\n",
        "            \n",
        "        Returns:\n",
        "            self: The fitted retriever\n",
        "        \"\"\"\n",
        "        print(\"Fitting TF-IDF vectorizer on evidence data...\")\n",
        "        start_time = time.time()\n",
        "        \n",
        "        # Save evidence IDs for later reference\n",
        "        self.evidence_ids = list(evidence_data.keys())\n",
        "        \n",
        "        # Preprocess evidence texts using the preprocess_text function\n",
        "        # Always remove stopwords\n",
        "        evidence_texts = [\n",
        "            preprocess_text(\n",
        "                text, \n",
        "                remove_stop_words=True, \n",
        "                lemmatize=self.lemmatize, \n",
        "                stem=self.stem\n",
        "            ) \n",
        "            for text in evidence_data.values()\n",
        "        ]\n",
        "        \n",
        "        # Create and fit the TF-IDF vectorizer\n",
        "        self.vectorizer = TfidfVectorizer(\n",
        "            max_features=self.max_features,\n",
        "            ngram_range=self.ngram_range,\n",
        "            stop_words='english'  # Always use English stopwords\n",
        "        )\n",
        "        \n",
        "        # Transform evidence texts to TF-IDF vectors\n",
        "        self.evidence_vectors = self.vectorizer.fit_transform(evidence_texts)\n",
        "        \n",
        "        fit_time = time.time() - start_time\n",
        "        print(f\"Fitted vectorizer with {self.evidence_vectors.shape[1]} features in {fit_time:.2f} seconds\")\n",
        "        print(f\"Created vectors for {self.evidence_vectors.shape[0]} evidence passages\")\n",
        "        \n",
        "        return self\n",
        "    \n",
        "    def retrieve(self, claim_text, top_k=None):\n",
        "        \"\"\"\n",
        "        Retrieve the most relevant evidence passages for a claim.\n",
        "        \n",
        "        Args:\n",
        "            claim_text: The text of the claim\n",
        "            top_k: Number of evidence passages to retrieve (overrides the default)\n",
        "            \n",
        "        Returns:\n",
        "            List of evidence IDs sorted by relevance\n",
        "        \"\"\"\n",
        "        if top_k is None:\n",
        "            top_k = self.top_k\n",
        "            \n",
        "        # Preprocess the claim using the preprocess_text function\n",
        "        # Always remove stopwords\n",
        "        processed_claim = preprocess_text(\n",
        "            claim_text, \n",
        "            remove_stop_words=True, \n",
        "            lemmatize=self.lemmatize, \n",
        "            stem=self.stem\n",
        "        )\n",
        "            \n",
        "        # Transform the claim to a TF-IDF vector\n",
        "        claim_vector = self.vectorizer.transform([processed_claim])\n",
        "        \n",
        "        # Calculate cosine similarity between the claim and all evidence passages\n",
        "        similarities = cosine_similarity(claim_vector, self.evidence_vectors)[0]\n",
        "        \n",
        "        # Get the indices of the top-k most similar evidence passages\n",
        "        top_indices = np.argsort(similarities)[-top_k:][::-1]\n",
        "        \n",
        "        # Return the corresponding evidence IDs\n",
        "        top_evidence_ids = [self.evidence_ids[idx] for idx in top_indices]\n",
        "        \n",
        "        return top_evidence_ids\n",
        "    \n",
        "    def retrieve_with_scores(self, claim_text, top_k=None, threshold=None):\n",
        "        \"\"\"\n",
        "        Retrieve the most relevant evidence passages for a claim, with similarity scores.\n",
        "        Optionally filter by a threshold.\n",
        "        \n",
        "        Args:\n",
        "            claim_text: The text of the claim\n",
        "            top_k: Number of evidence passages to retrieve (overrides the default)\n",
        "            threshold: Minimum similarity score to include (default: None)\n",
        "            \n",
        "        Returns:\n",
        "            List of tuples (evidence_id, similarity_score) sorted by relevance\n",
        "        \"\"\"\n",
        "        if top_k is None:\n",
        "            top_k = self.top_k\n",
        "            \n",
        "        # Preprocess the claim using the preprocess_text function\n",
        "        # Always remove stopwords\n",
        "        processed_claim = preprocess_text(\n",
        "            claim_text, \n",
        "            remove_stop_words=True, \n",
        "            lemmatize=self.lemmatize, \n",
        "            stem=self.stem\n",
        "        )\n",
        "            \n",
        "        # Transform the claim to a TF-IDF vector\n",
        "        claim_vector = self.vectorizer.transform([processed_claim])\n",
        "        \n",
        "        # Calculate cosine similarity between the claim and all evidence passages\n",
        "        similarities = cosine_similarity(claim_vector, self.evidence_vectors)[0]\n",
        "        \n",
        "        # Get the indices of the top-k most similar evidence passages\n",
        "        top_indices = np.argsort(similarities)[-top_k:][::-1]\n",
        "        \n",
        "        # Create a list of (evidence_id, score) tuples\n",
        "        results = [(self.evidence_ids[idx], similarities[idx]) for idx in top_indices]\n",
        "        \n",
        "        # Filter by threshold if specified\n",
        "        if threshold is not None:\n",
        "            results = [(eid, score) for eid, score in results if score >= threshold]\n",
        "            \n",
        "        return results\n",
        "    \n",
        "    def get_top_terms(self, text, n=10):\n",
        "        \"\"\"\n",
        "        Get the top terms in a text based on TF-IDF weights.\n",
        "        Useful for understanding what terms are important in claims/evidence.\n",
        "        \n",
        "        Args:\n",
        "            text: The text to analyze\n",
        "            n: Number of top terms to return\n",
        "            \n",
        "        Returns:\n",
        "            List of (term, tfidf_weight) tuples\n",
        "        \"\"\"\n",
        "        # Preprocess the text using the preprocess_text function\n",
        "        # Always remove stopwords\n",
        "        processed_text = preprocess_text(\n",
        "            text, \n",
        "            remove_stop_words=True, \n",
        "            lemmatize=self.lemmatize, \n",
        "            stem=self.stem\n",
        "        )\n",
        "            \n",
        "        # Transform the text to a TF-IDF vector\n",
        "        text_vector = self.vectorizer.transform([processed_text])\n",
        "        \n",
        "        # Get the feature names (terms)\n",
        "        feature_names = self.vectorizer.get_feature_names_out()\n",
        "        \n",
        "        # Get the TF-IDF weights for the text\n",
        "        tfidf_weights = text_vector.toarray()[0]\n",
        "        \n",
        "        # Sort terms by TF-IDF weight and get the top n\n",
        "        top_indices = np.argsort(tfidf_weights)[-n:][::-1]\n",
        "        top_terms = [(feature_names[idx], tfidf_weights[idx]) for idx in top_indices]\n",
        "        \n",
        "        return top_terms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define evaluation function for the evidence retriever\n",
        "def evaluate_retriever(retriever, labeled_claims, evidence_data):\n",
        "    \"\"\"\n",
        "    Evaluate the evidence retriever on labeled data.\n",
        "    \n",
        "    Args:\n",
        "        retriever: The fitted evidence retriever\n",
        "        labeled_claims: Dictionary of labeled claims with ground truth evidence\n",
        "        evidence_data: Dictionary of evidence passages\n",
        "        \n",
        "    Returns:\n",
        "        Dictionary with evaluation metrics (precision, recall, f1)\n",
        "    \"\"\"\n",
        "    print(\"Evaluating retriever...\")\n",
        "    total_precision = 0\n",
        "    total_recall = 0\n",
        "    total_f1 = 0\n",
        "    \n",
        "    # Using a simple loop without tqdm to avoid any import issues\n",
        "    for claim_id, claim_info in labeled_claims.items():\n",
        "        claim_text = claim_info['claim_text']\n",
        "        true_evidence_ids = claim_info.get('evidences', [])\n",
        "        \n",
        "        # Skip claims without evidence\n",
        "        if not true_evidence_ids:\n",
        "            continue\n",
        "        \n",
        "        # Retrieve evidence using the retriever\n",
        "        retrieved_evidence_ids = retriever.retrieve(claim_text)\n",
        "        \n",
        "        # Calculate precision, recall, and F1\n",
        "        true_positives = set(retrieved_evidence_ids).intersection(set(true_evidence_ids))\n",
        "        precision = len(true_positives) / len(retrieved_evidence_ids) if retrieved_evidence_ids else 0\n",
        "        recall = len(true_positives) / len(true_evidence_ids) if true_evidence_ids else 0\n",
        "        \n",
        "        f1 = 0\n",
        "        if precision + recall > 0:\n",
        "            f1 = 2 * precision * recall / (precision + recall)\n",
        "        \n",
        "        total_precision += precision\n",
        "        total_recall += recall\n",
        "        total_f1 += f1\n",
        "    \n",
        "    n_claims = len(labeled_claims)\n",
        "    avg_precision = total_precision / n_claims\n",
        "    avg_recall = total_recall / n_claims\n",
        "    avg_f1 = total_f1 / n_claims\n",
        "    \n",
        "    print(f\"Avg Precision: {avg_precision:.4f}\")\n",
        "    print(f\"Avg Recall: {avg_recall:.4f}\")\n",
        "    print(f\"Avg F1: {avg_f1:.4f}\")\n",
        "    \n",
        "    return {\n",
        "        'precision': avg_precision,\n",
        "        'recall': avg_recall,\n",
        "        'f1': avg_f1\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### TFIDF configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting basic TF-IDF retriever...\n",
            "Fitting TF-IDF vectorizer on evidence data...\n",
            "Fitted vectorizer with 10000 features in 553.83 seconds\n",
            "Created vectors for 1208827 evidence passages\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<__main__.TfidfEvidenceRetriever at 0x1819d4a2090>"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create the TF-IDF evidence retriever with basic configuration\n",
        "retriever_basic = TfidfEvidenceRetriever(\n",
        "    max_features=10000,\n",
        "    ngram_range=(1, 2),\n",
        "    top_k=3,\n",
        "    lemmatize=True,\n",
        "    stem=False\n",
        ")\n",
        "\n",
        "# Fit the retriever on the evidence data\n",
        "print(\"Fitting basic TF-IDF retriever...\")\n",
        "retriever_basic.fit(evidence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating retriever...\n",
            "Avg Precision: 0.0736\n",
            "Avg Recall: 0.0817\n",
            "Avg F1: 0.0712\n",
            "Basic TF-IDF results: {'precision': 0.0735930735930736, 'recall': 0.08170995670995672, 'f1': 0.07122758194186767}\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the basic retriever on the development set\n",
        "dev_results_basic = evaluate_retriever(retriever_basic, dev_claims, evidence)\n",
        "print(f\"Basic TF-IDF results: {dev_results_basic}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # Examine an example claim and retrieved evidence\n",
        "\n",
        "# # Select a sample claim from the development set\n",
        "# sample_claim_id = next(iter(dev_claims))\n",
        "# sample_claim = dev_claims[sample_claim_id]['claim_text']\n",
        "# print(f\"Sample claim: {sample_claim}\")\n",
        "\n",
        "# # Retrieve evidence for this claim\n",
        "# top_evidence_ids = retriever_basic.retrieve(sample_claim)\n",
        "# print(f\"Top evidence IDs: {top_evidence_ids}\")\n",
        "\n",
        "# # Print the retrieved evidence texts\n",
        "# print(\"\\nRetrieved evidence texts:\")\n",
        "# for i, eid in enumerate(top_evidence_ids):\n",
        "#     print(f\"{i+1}. {evidence[eid]}\")\n",
        "\n",
        "# # Get ground truth evidence\n",
        "# true_evidence_ids = dev_claims[sample_claim_id].get('evidences', [])\n",
        "# print(f\"\\nGround truth evidence IDs: {true_evidence_ids}\")\n",
        "\n",
        "# # Print the ground truth evidence texts\n",
        "# print(\"\\nGround truth evidence texts:\")\n",
        "# for i, eid in enumerate(true_evidence_ids):\n",
        "#     print(f\"{i+1}. {evidence[eid]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # Optional: Experiment with stemming and lemmatization\n",
        "\n",
        "# # Create a retriever with stemming\n",
        "# retriever_stemming = TfidfEvidenceRetriever(\n",
        "#     max_features=10000,\n",
        "#     ngram_range=(1, 2),\n",
        "#     top_k=3,\n",
        "#     lemmatize=False,\n",
        "#     stem=True\n",
        "# )\n",
        "\n",
        "# print(\"Fitting retriever with stemming...\")\n",
        "# retriever_stemming.fit(evidence)\n",
        "# dev_results_stemming = evaluate_retriever(retriever_stemming, dev_claims, evidence)\n",
        "# print(f\"Stemming results: {dev_results_stemming}\")\n",
        "\n",
        "# # Create a retriever with lemmatization\n",
        "# retriever_lemma = TfidfEvidenceRetriever(\n",
        "#     max_features=10000,\n",
        "#     ngram_range=(1, 2),\n",
        "#     top_k=3,\n",
        "#     lemmatize=True,\n",
        "#     stem=False\n",
        "# )\n",
        "\n",
        "# print(\"Fitting retriever with lemmatization...\")\n",
        "# retriever_lemma.fit(evidence)\n",
        "# dev_results_lemma = evaluate_retriever(retriever_lemma, dev_claims, evidence)\n",
        "# print(f\"Lemmatization results: {dev_results_lemma}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # Optional: Experiment with different top-k values\n",
        "# top_k_values = [3, 5, 6, 10]\n",
        "# top_k_results = {}\n",
        "\n",
        "# # Use the best preprocessing approach based on earlier experiments\n",
        "# best_retriever = retriever_basic  # Replace with the best performing retriever if different\n",
        "\n",
        "# for k in top_k_values:\n",
        "#     print(f\"\\nEvaluating with top_k = {k}\")\n",
        "    \n",
        "#     # We don't need to retrain the model, just change the retrieval parameter\n",
        "#     total_precision = 0\n",
        "#     total_recall = 0\n",
        "#     total_f1 = 0\n",
        "    \n",
        "#     for claim_id, claim_info in tqdm(dev_claims.items()):\n",
        "#         claim_text = claim_info['claim_text']\n",
        "#         true_evidence_ids = claim_info.get('evidences', [])\n",
        "        \n",
        "#         # Skip claims without evidence\n",
        "#         if not true_evidence_ids:\n",
        "#             continue\n",
        "        \n",
        "#         # Retrieve evidence with current k value\n",
        "#         retrieved_evidence_ids = best_retriever.retrieve(claim_text, top_k=k)\n",
        "        \n",
        "#         # Calculate metrics\n",
        "#         true_positives = set(retrieved_evidence_ids).intersection(set(true_evidence_ids))\n",
        "#         precision = len(true_positives) / len(retrieved_evidence_ids) if retrieved_evidence_ids else 0\n",
        "#         recall = len(true_positives) / len(true_evidence_ids) if true_evidence_ids else 0\n",
        "        \n",
        "#         f1 = 0\n",
        "#         if precision + recall > 0:\n",
        "#             f1 = 2 * precision * recall / (precision + recall)\n",
        "        \n",
        "#         total_precision += precision\n",
        "#         total_recall += recall\n",
        "#         total_f1 += f1\n",
        "    \n",
        "#     n_claims = len(dev_claims)\n",
        "#     avg_precision = total_precision / n_claims\n",
        "#     avg_recall = total_recall / n_claims\n",
        "#     avg_f1 = total_f1 / n_claims\n",
        "    \n",
        "#     print(f\"top_k={k}: Precision={avg_precision:.4f}, Recall={avg_recall:.4f}, F1={avg_f1:.4f}\")\n",
        "    \n",
        "#     top_k_results[k] = {\n",
        "#         'precision': avg_precision,\n",
        "#         'recall': avg_recall,\n",
        "#         'f1': avg_f1\n",
        "#     }\n",
        "\n",
        "# # Visualize top-k results\n",
        "# plt.figure(figsize=(10, 6))\n",
        "# ks = list(top_k_results.keys())\n",
        "# precision = [top_k_results[k]['precision'] for k in ks]\n",
        "# recall = [top_k_results[k]['recall'] for k in ks]\n",
        "# f1 = [top_k_results[k]['f1'] for k in ks]\n",
        "\n",
        "# plt.plot(ks, precision, 'o-', label='Precision')\n",
        "# plt.plot(ks, recall, 's-', label='Recall')\n",
        "# plt.plot(ks, f1, '^-', label='F1')\n",
        "# plt.xlabel('top-k')\n",
        "# plt.ylabel('Score')\n",
        "# plt.title('Retrieval Performance vs. Number of Retrieved Passages')\n",
        "# plt.legend()\n",
        "# plt.grid(True)\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Task 2 LSTM classification task\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define constants for the classification task\n",
        "LABEL_MAP = {\n",
        "    'SUPPORTS': 0,\n",
        "    'REFUTES': 1,\n",
        "    'NOT_ENOUGH_INFO': 2,\n",
        "    'DISPUTED': 3\n",
        "}\n",
        "\n",
        "REVERSE_LABEL_MAP = {v: k for k, v in LABEL_MAP.items()}\n",
        "\n",
        "# Parameters for the model and training\n",
        "MAX_SEQUENCE_LENGTH = 300  # Maximum length of combined claim and evidence text\n",
        "EMBEDDING_DIM = 50        # Dimension of word embeddings\n",
        "HIDDEN_DIM = 64           # Dimension of LSTM hidden states \n",
        "BATCH_SIZE = 32            # Batch size for training \n",
        "LEARNING_RATE = 0.001      # Learning rate for optimizer \n",
        "NUM_EPOCHS = 8            # Number of training epochs\n",
        "DROPOUT_RATE = 0.3         # Dropout rate \n",
        "NUM_LAYERS= 1            # Number of LSTM layers \n",
        "NOICE_RATIO = 0.3 # Ratio of noise to add to the input "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a vocabulary from the training data\n",
        "def build_vocabulary(train_claims, evidence_data, max_size=20000):\n",
        "    \"\"\"\n",
        "    Build a vocabulary from the training data.\n",
        "    \n",
        "    Args:\n",
        "        train_claims: Dictionary of training claims\n",
        "        evidence_data: Dictionary of evidence passages\n",
        "        max_size: Maximum vocabulary size\n",
        "        \n",
        "    Returns:\n",
        "        word_to_idx: Dictionary mapping words to indices\n",
        "        idx_to_word: Dictionary mapping indices to words\n",
        "    \"\"\"\n",
        "    print(\"Building vocabulary...\")\n",
        "    word_counts = Counter()\n",
        "    \n",
        "    # Process claim texts\n",
        "    for claim_info in train_claims.values():\n",
        "        claim_text = claim_info['claim_text']\n",
        "        processed_text = preprocess_text(claim_text, remove_stop_words=True)\n",
        "        word_counts.update(processed_text.split())\n",
        "    \n",
        "    # Process evidence texts (sample to avoid processing all evidence)\n",
        "    evidence_sample = list(evidence_data.values())\n",
        "    if len(evidence_sample) > 10000:\n",
        "        import random\n",
        "        random.seed(42)\n",
        "        evidence_sample = random.sample(evidence_sample, 10000)\n",
        "    \n",
        "    for evidence_text in evidence_sample:\n",
        "        processed_text = preprocess_text(evidence_text, remove_stop_words=True, lemmatize=False, stem=False)\n",
        "        word_counts.update(processed_text.split())\n",
        "    \n",
        "    # Create vocabulary with special tokens and most common words\n",
        "    vocab = ['<PAD>', '<UNK>']  # Add special tokens\n",
        "    vocab.extend([word for word, count in word_counts.most_common(max_size - len(vocab))])\n",
        "    \n",
        "    # Create word-to-index and index-to-word mappings\n",
        "    word_to_idx = {word: idx for idx, word in enumerate(vocab)}\n",
        "    idx_to_word = {idx: word for word, idx in word_to_idx.items()}\n",
        "    \n",
        "    print(f\"Vocabulary size: {len(word_to_idx)}\")\n",
        "    return word_to_idx, idx_to_word"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ClaimDataset(Dataset):\n",
        "    \"\"\"Dataset for claim classification with bias exposure during training.\"\"\"\n",
        "    def __init__(self, claims_data, evidence_data, word_to_idx, max_length=MAX_SEQUENCE_LENGTH, \n",
        "                 use_retrieved_evidence=True, training_mode=False, noise_ratio=0.2):\n",
        "        self.texts = []\n",
        "        self.labels = []\n",
        "        self.claim_ids = []\n",
        "        self.max_length = max_length\n",
        "        self.word_to_idx = word_to_idx\n",
        "        self.pad_idx = word_to_idx['<PAD>']\n",
        "        self.unk_idx = word_to_idx['<UNK>']\n",
        "        self.training_mode = training_mode\n",
        "        self.noise_ratio = noise_ratio\n",
        "        \n",
        "        # Process each claim\n",
        "        for claim_id, claim_info in claims_data.items():\n",
        "            claim_text = claim_info['claim_text']\n",
        "            \n",
        "            # Get evidence IDs - either from retriever or ground truth\n",
        "            if use_retrieved_evidence and 'retrieved_evidences' in claim_info:\n",
        "                evidence_ids = claim_info['retrieved_evidences']\n",
        "            else:\n",
        "                evidence_ids = claim_info.get('evidences', [])\n",
        "            \n",
        "            # Get evidence texts\n",
        "            evidence_texts = [evidence_data.get(eid, \"\") for eid in evidence_ids]\n",
        "            \n",
        "            # If in training mode, add some incorrect evidence (bias exposure)\n",
        "            if training_mode and 'claim_label' in claim_info and evidence_ids:\n",
        "                evidence_texts = self._add_noise_evidence(evidence_texts, evidence_data, evidence_ids)\n",
        "            \n",
        "            # Combine claim and evidence\n",
        "            combined_text = claim_text + \" \" + \" \".join(evidence_texts)\n",
        "            processed_text = preprocess_text(combined_text, remove_stop_words=True, lemmatize=False, stem=False)\n",
        "            \n",
        "            # Convert words to indices\n",
        "            tokens = processed_text.split()\n",
        "            indices = [self.word_to_idx.get(word, self.unk_idx) for word in tokens[:max_length]]\n",
        "            \n",
        "            # Pad or truncate\n",
        "            if len(indices) < max_length:\n",
        "                indices = indices + [self.pad_idx] * (max_length - len(indices))\n",
        "            else:\n",
        "                indices = indices[:max_length]\n",
        "            \n",
        "            # Get label if available (for training/dev)\n",
        "            if 'claim_label' in claim_info:\n",
        "                label = LABEL_MAP[claim_info['claim_label']]\n",
        "            else:\n",
        "                label = -1  # For test data\n",
        "            \n",
        "            self.claim_ids.append(claim_id)\n",
        "            self.texts.append(indices)\n",
        "            self.labels.append(label)\n",
        "    \n",
        "    def _add_noise_evidence(self, correct_evidence_texts, evidence_data, correct_ids):\n",
        "        \"\"\"Add some incorrect evidence to simulate retrieval errors.\"\"\"\n",
        "        import random\n",
        "        \n",
        "        # Calculate number of incorrect evidence to add\n",
        "        num_incorrect = max(1, int(len(correct_evidence_texts) * self.noise_ratio))\n",
        "        \n",
        "        # Sample from all evidence IDs excluding the correct ones\n",
        "        all_evidence_ids = list(evidence_data.keys())\n",
        "        incorrect_ids = [eid for eid in all_evidence_ids if eid not in correct_ids]\n",
        "        \n",
        "        # Only add noise if we have enough evidence to sample from\n",
        "        if incorrect_ids:\n",
        "            sampled_incorrect = random.sample(incorrect_ids, min(num_incorrect, len(incorrect_ids)))\n",
        "            incorrect_texts = [evidence_data[eid] for eid in sampled_incorrect]\n",
        "            \n",
        "            # Mix the correct and incorrect evidence\n",
        "            mixed_evidence = correct_evidence_texts + incorrect_texts\n",
        "            random.shuffle(mixed_evidence)  # Shuffle to avoid positional bias\n",
        "            \n",
        "            return mixed_evidence\n",
        "        else:\n",
        "            return correct_evidence_texts\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.claim_ids)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        return {\n",
        "            'claim_id': self.claim_ids[idx],\n",
        "            'text': torch.tensor(self.texts[idx], dtype=torch.long),\n",
        "            'label': torch.tensor(self.labels[idx], dtype=torch.long)\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # Create a PyTorch dataset for claim classification\n",
        "# class ClaimClassificationDataset(Dataset):\n",
        "#     def __init__(self, claims_data, evidence_data, word_to_idx, \n",
        "#                  max_length=MAX_SEQUENCE_LENGTH, use_retrieved_evidence=True):\n",
        "#         \"\"\"\n",
        "#         Dataset for claim classification.\n",
        "        \n",
        "#         Args:\n",
        "#             claims_data: Dictionary of claims\n",
        "#             evidence_data: Dictionary of evidence passages\n",
        "#             word_to_idx: Vocabulary mapping\n",
        "#             max_length: Maximum sequence length\n",
        "#             use_retrieved_evidence: If True, use retrieved evidence; if False, use ground truth evidence\n",
        "#         \"\"\"\n",
        "#         self.claims = []\n",
        "#         self.texts = []\n",
        "#         self.labels = []\n",
        "#         self.max_length = max_length\n",
        "#         self.word_to_idx = word_to_idx\n",
        "#         self.pad_idx = word_to_idx['<PAD>']\n",
        "#         self.unk_idx = word_to_idx['<UNK>']\n",
        "        \n",
        "#         print(\"Preparing classification dataset...\")\n",
        "        \n",
        "#         for claim_id, claim_info in claims_data.items():\n",
        "#             claim_text = claim_info['claim_text']\n",
        "            \n",
        "#             # Get evidence IDs and corresponding texts\n",
        "#             if use_retrieved_evidence and 'retrieved_evidences' in claim_info:\n",
        "#                 evidence_ids = claim_info['retrieved_evidences']\n",
        "#             else:\n",
        "#                 evidence_ids = claim_info.get('evidences', [])\n",
        "            \n",
        "#             evidence_texts = [evidence_data.get(eid, \"\") for eid in evidence_ids]\n",
        "            \n",
        "#             # Skip if no evidence (for training data)\n",
        "#             if not evidence_texts and 'claim_label' in claim_info:\n",
        "#                 continue\n",
        "            \n",
        "#             # Combine claim and evidence texts\n",
        "#             combined_text = claim_text + \" \" + \" \".join(evidence_texts)\n",
        "            \n",
        "#             # Preprocess and tokenize\n",
        "#             processed_text = preprocess_text(combined_text, remove_stop_words=True)\n",
        "#             tokens = processed_text.split()\n",
        "            \n",
        "#             # Convert tokens to indices\n",
        "#             indices = [self.word_to_idx.get(token, self.unk_idx) for token in tokens[:self.max_length]]\n",
        "            \n",
        "#             # Pad or truncate to max_length\n",
        "#             if len(indices) < self.max_length:\n",
        "#                 indices = indices + [self.pad_idx] * (self.max_length - len(indices))\n",
        "#             else:\n",
        "#                 indices = indices[:self.max_length]\n",
        "            \n",
        "#             # Get label (if available)\n",
        "#             if 'claim_label' in claim_info:\n",
        "#                 label = LABEL_MAP[claim_info['claim_label']]\n",
        "#             else:\n",
        "#                 label = -1  # For test data\n",
        "            \n",
        "#             self.claims.append(claim_id)\n",
        "#             self.texts.append(indices)\n",
        "#             self.labels.append(label)\n",
        "    \n",
        "#     def __len__(self):\n",
        "#         return len(self.claims)\n",
        "    \n",
        "#     def __getitem__(self, idx):\n",
        "#         return {\n",
        "#             'claim_id': self.claims[idx],\n",
        "#             'text': torch.tensor(self.texts[idx], dtype=torch.long),\n",
        "#             'label': torch.tensor(self.labels[idx], dtype=torch.long)\n",
        "#         }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define the LSTM model for claim classification with enhanced regularization\n",
        "class LSTMClassifier(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, dropout_rate=0.4,\n",
        "                bidirectional=True, num_layers=1):\n",
        "        \"\"\"\n",
        "        LSTM-based classifier for claim verification with enhanced regularization.\n",
        "        \n",
        "        Args:\n",
        "            vocab_size: Size of the vocabulary\n",
        "            embedding_dim: Dimension of word embeddings\n",
        "            hidden_dim: Dimension of LSTM hidden states\n",
        "            output_dim: Number of output classes\n",
        "            dropout_rate: Dropout rate for regularization\n",
        "            bidirectional: Whether to use bidirectional LSTM\n",
        "            num_layers: Number of LSTM layers\n",
        "        \"\"\"\n",
        "        super(LSTMClassifier, self).__init__()\n",
        "        \n",
        "        # Add embedding layer with dropout\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
        "        self.emb_dropout = nn.Dropout(dropout_rate/2)  # Lighter dropout for embeddings\n",
        "        \n",
        "        # LSTM layer with existing parameters\n",
        "        self.lstm = nn.LSTM(embedding_dim,\n",
        "                          hidden_dim,\n",
        "                          num_layers=num_layers,\n",
        "                          bidirectional=bidirectional,\n",
        "                          dropout=dropout_rate if num_layers > 1 else 0,\n",
        "                          batch_first=True)\n",
        "        \n",
        "        # If bidirectional, hidden_dim is doubled\n",
        "        self.fc_dim = hidden_dim * 2 if bidirectional else hidden_dim\n",
        "        \n",
        "        # # Add batch normalization between LSTM and FC layer (helps stabilize training)\n",
        "        # self.batch_norm = nn.BatchNorm1d(self.fc_dim)\n",
        "        \n",
        "        # Existing FC layers with increased dropout\n",
        "        self.fc1 = nn.Linear(self.fc_dim, hidden_dim)\n",
        "        self.dropout1 = nn.Dropout(dropout_rate)  # After first FC layer\n",
        "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
        "        \n",
        "    def forward(self, text):\n",
        "        # text: [batch_size, seq_len]\n",
        "        \n",
        "        # Apply embedding with dropout\n",
        "        embedded = self.embedding(text)  # [batch_size, seq_len, embedding_dim]\n",
        "        embedded = self.emb_dropout(embedded)  # Apply dropout to embeddings\n",
        "        \n",
        "        # Push through LSTM\n",
        "        output, (hidden, cell) = self.lstm(embedded)  # output: [batch_size, seq_len, hidden_dim*2]\n",
        "        \n",
        "        # Use the final hidden state of each direction\n",
        "        if self.lstm.bidirectional:\n",
        "            hidden = torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim=1)  # [batch_size, hidden_dim*2]\n",
        "        else:\n",
        "            hidden = hidden[-1,:,:]  # [batch_size, hidden_dim]\n",
        "        \n",
        "        # # Apply batch normalization\n",
        "        # hidden = self.batch_norm(hidden)\n",
        "        \n",
        "        # Push through fully connected layers with enhanced regularization\n",
        "        dense1 = torch.relu(self.fc1(hidden))\n",
        "        dense1 = self.dropout1(dense1)  # Apply dropout\n",
        "        output = self.fc2(dense1)  # [batch_size, output_dim]\n",
        "        \n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Function to train the model\n",
        "def train_model(model, train_loader, valid_loader, optimizer, criterion, num_epochs=NUM_EPOCHS):\n",
        "    \"\"\"\n",
        "    Train the classification model.\n",
        "    \n",
        "    Args:\n",
        "        model: The LSTM model\n",
        "        train_loader: DataLoader for training data\n",
        "        valid_loader: DataLoader for validation data\n",
        "        optimizer: Optimizer for parameter updates\n",
        "        criterion: Loss function\n",
        "        num_epochs: Number of training epochs\n",
        "        \n",
        "    Returns:\n",
        "        List of training losses, training accuracies, validation losses, validation accuracies\n",
        "    \"\"\"\n",
        "    # Make sure model is on the correct device\n",
        "    model = model.to(device)\n",
        "    \n",
        "    # Track metrics\n",
        "    train_losses = []\n",
        "    train_accs = []\n",
        "    valid_losses = []\n",
        "    valid_accs = []\n",
        "    \n",
        "    for epoch in range(num_epochs):\n",
        "        # Training phase\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        \n",
        "        for batch in train_loader:\n",
        "            # Move batch to device\n",
        "            text = batch['text'].to(device)\n",
        "            labels = batch['label'].to(device)\n",
        "            \n",
        "            # Zero the gradients\n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            # Forward pass\n",
        "            outputs = model(text)\n",
        "            \n",
        "            # Calculate loss\n",
        "            loss = criterion(outputs, labels)\n",
        "            \n",
        "            # Backward pass and optimize\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "            # Update metrics\n",
        "            train_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "        \n",
        "        # Calculate epoch metrics\n",
        "        epoch_loss = train_loss / len(train_loader)\n",
        "        epoch_acc = 100 * correct / total\n",
        "        train_losses.append(epoch_loss)\n",
        "        train_accs.append(epoch_acc)\n",
        "        \n",
        "        # Validation phase\n",
        "        model.eval()\n",
        "        valid_loss = 0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            for batch in valid_loader:\n",
        "                # Move batch to device\n",
        "                text = batch['text'].to(device)\n",
        "                labels = batch['label'].to(device)\n",
        "                \n",
        "                # Forward pass\n",
        "                outputs = model(text)\n",
        "                \n",
        "                # Calculate loss\n",
        "                loss = criterion(outputs, labels)\n",
        "                \n",
        "                # Update metrics\n",
        "                valid_loss += loss.item()\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "        \n",
        "        # Calculate epoch metrics\n",
        "        epoch_loss = valid_loss / len(valid_loader)\n",
        "        epoch_acc = 100 * correct / total\n",
        "        valid_losses.append(epoch_loss)\n",
        "        valid_accs.append(epoch_acc)\n",
        "        \n",
        "        print(f\"Epoch {epoch+1}/{num_epochs}, \"\n",
        "              f\"Train Loss: {train_losses[-1]:.4f}, Train Acc: {train_accs[-1]:.2f}%, \"\n",
        "              f\"Valid Loss: {valid_losses[-1]:.4f}, Valid Acc: {valid_accs[-1]:.2f}%\")\n",
        "    \n",
        "    return train_losses, train_accs, valid_losses, valid_accs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Function to evaluate model on development set\n",
        "def evaluate_model(model, data_loader):\n",
        "    \"\"\"\n",
        "    Evaluate the model on a dataset.\n",
        "    \n",
        "    Args:\n",
        "        model: The trained model\n",
        "        data_loader: DataLoader for evaluation data\n",
        "        \n",
        "    Returns:\n",
        "        Dictionary with evaluation metrics\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    predictions = {}\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for batch in data_loader:\n",
        "            # Move batch to device\n",
        "            text = batch['text'].to(device)\n",
        "            labels = batch['label'].to(device)\n",
        "            claim_ids = batch['claim_id']\n",
        "            \n",
        "            # Forward pass\n",
        "            outputs = model(text)\n",
        "            \n",
        "            # Get predictions\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            \n",
        "            # Update metrics\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "            \n",
        "            # Save predictions\n",
        "            for i, claim_id in enumerate(claim_ids):\n",
        "                pred_idx = predicted[i].item()\n",
        "                predictions[claim_id] = REVERSE_LABEL_MAP[pred_idx]\n",
        "    \n",
        "    accuracy = 100 * correct / total if total > 0 else 0\n",
        "    print(f\"Evaluation Accuracy: {accuracy:.2f}%\")\n",
        "    \n",
        "    return {\n",
        "        'accuracy': accuracy,\n",
        "        'predictions': predictions\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Function to make predictions on test set\n",
        "def predict(model, data_loader):\n",
        "    \"\"\"\n",
        "    Make predictions on a dataset.\n",
        "    \n",
        "    Args:\n",
        "        model: The trained model\n",
        "        data_loader: DataLoader for prediction data\n",
        "        \n",
        "    Returns:\n",
        "        Dictionary mapping claim IDs to predicted labels\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    predictions = {}\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for batch in data_loader:\n",
        "            # Move batch to device\n",
        "            text = batch['text'].to(device)\n",
        "            claim_ids = batch['claim_id']\n",
        "            \n",
        "            # Forward pass\n",
        "            outputs = model(text)\n",
        "            \n",
        "            # Get predictions\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            \n",
        "            # Save predictions\n",
        "            for i, claim_id in enumerate(claim_ids):\n",
        "                pred_idx = predicted[i].item()\n",
        "                predictions[claim_id] = REVERSE_LABEL_MAP[pred_idx]\n",
        "    \n",
        "    return predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EzGuzHPE87Ya"
      },
      "source": [
        "# 3.Testing and Evaluation\n",
        "(You can add as many code blocks and text blocks as you need. However, YOU SHOULD NOT MODIFY the section title)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "6ZVeNYIH9IaL"
      },
      "outputs": [],
      "source": [
        "# Run the training and evaluation process\n",
        "def run_claim_classification(\n",
        "    train_claims, dev_claims, test_claims, evidence, retriever=None\n",
        "):\n",
        "    \"\"\"\n",
        "    Run the entire claim classification pipeline: build vocabulary, prepare datasets,\n",
        "    train and evaluate model, make predictions.\n",
        "\n",
        "    Args:\n",
        "        train_claims: Dictionary of training claims\n",
        "        dev_claims: Dictionary of development claims\n",
        "        test_claims: Dictionary of test claims\n",
        "        evidence: Dictionary of evidence passages\n",
        "        retriever: Evidence retriever to get evidence for claims (if None, use ground truth)\n",
        "\n",
        "    Returns:\n",
        "        dev_predictions: Predictions on development set\n",
        "        test_predictions: Predictions on test set\n",
        "    \"\"\"\n",
        "    # Step 1: Retrieve evidence for claims (if retriever is provided)\n",
        "    if retriever:\n",
        "        print(\"Retrieving evidence for claims...\")\n",
        "        for split_name, claims in [\n",
        "            (\"training\", train_claims),\n",
        "            (\"development\", dev_claims),\n",
        "            (\"test\", test_claims),\n",
        "        ]:\n",
        "            print(f\"Processing {split_name} claims...\")\n",
        "            for claim_id, claim_info in claims.items():\n",
        "                claim_text = claim_info[\"claim_text\"]\n",
        "                retrieved_evidence = retriever.retrieve(claim_text)\n",
        "                claims[claim_id][\"retrieved_evidences\"] = retrieved_evidence\n",
        "\n",
        "    # Step 2: Build vocabulary\n",
        "    word_to_idx, idx_to_word = build_vocabulary(train_claims, evidence)\n",
        "\n",
        "    # Step 3: Prepare datasets\n",
        "    use_retrieved = retriever is not None\n",
        "\n",
        "    # Create datasets with bias exposure for training\n",
        "    train_dataset = ClaimDataset(\n",
        "        train_claims,\n",
        "        evidence,\n",
        "        word_to_idx,\n",
        "        use_retrieved_evidence=use_retrieved,\n",
        "        training_mode=True,  # Enable bias exposure\n",
        "        noise_ratio=NOICE_RATIO,\n",
        "    )  # Add 30% noise\n",
        "\n",
        "    # Split training data for validation\n",
        "    train_size = int(0.9 * len(train_dataset))\n",
        "    val_size = len(train_dataset) - train_size\n",
        "    train_subset, val_subset = torch.utils.data.random_split(\n",
        "        train_dataset,\n",
        "        [train_size, val_size],\n",
        "        generator=torch.Generator().manual_seed(42),\n",
        "    )\n",
        "\n",
        "    # For development and test, don't add noise\n",
        "    dev_dataset = ClaimDataset(\n",
        "        dev_claims,\n",
        "        evidence,\n",
        "        word_to_idx,\n",
        "        use_retrieved_evidence=use_retrieved,\n",
        "        training_mode=False,\n",
        "    )  # No noise for evaluation\n",
        "    test_dataset = ClaimDataset(\n",
        "        test_claims,\n",
        "        evidence,\n",
        "        word_to_idx,\n",
        "        use_retrieved_evidence=use_retrieved,\n",
        "        training_mode=False,\n",
        "    )  # No noise for testing\n",
        "\n",
        "    # Create data loaders\n",
        "    train_loader = DataLoader(train_subset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "    val_loader = DataLoader(val_subset, batch_size=BATCH_SIZE)\n",
        "    dev_loader = DataLoader(dev_dataset, batch_size=BATCH_SIZE)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)\n",
        "\n",
        "    # Step 5: Initialize model, loss function, and optimizer\n",
        "    model = LSTMClassifier(\n",
        "        vocab_size=len(word_to_idx),\n",
        "        embedding_dim=EMBEDDING_DIM,\n",
        "        hidden_dim=HIDDEN_DIM,\n",
        "        output_dim=len(LABEL_MAP),\n",
        "        dropout_rate=DROPOUT_RATE,\n",
        "        bidirectional=True,\n",
        "        num_layers=NUM_LAYERS,\n",
        "    )\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=1e-4)\n",
        "\n",
        "    # Step 6: Train model\n",
        "    print(\"\\nTraining LSTM classifier...\")\n",
        "    # Use val_loader (internal validation) instead of dev_loader during training\n",
        "    history = train_model(\n",
        "        model, train_loader, val_loader, optimizer, criterion, num_epochs=NUM_EPOCHS\n",
        "    )\n",
        "\n",
        "    # Step 7: After training, evaluate on the development set\n",
        "    print(\"\\nEvaluating on development set...\")\n",
        "    dev_results = evaluate_model(model, dev_loader)\n",
        "\n",
        "    # Step 8: Predict on test set\n",
        "    print(\"\\nPredicting on test set...\")\n",
        "    test_predictions = predict(model, test_loader)\n",
        "\n",
        "    # Step 9: Prepare prediction dictionaries with both labels and evidence\n",
        "    dev_predictions = {}\n",
        "    for claim_id, label in dev_results[\"predictions\"].items():\n",
        "        evidence_ids = (\n",
        "            dev_claims[claim_id].get(\"retrieved_evidences\", [])\n",
        "            if use_retrieved\n",
        "            else dev_claims[claim_id].get(\"evidences\", [])\n",
        "        )\n",
        "        dev_predictions[claim_id] = {\n",
        "            \"claim_text\": dev_claims[claim_id][\"claim_text\"],\n",
        "            \"claim_label\": label,\n",
        "            \"evidences\": evidence_ids,\n",
        "        }\n",
        "\n",
        "    test_predictions_dict = {}\n",
        "    for claim_id, label in test_predictions.items():\n",
        "        evidence_ids = (\n",
        "            test_claims[claim_id].get(\"retrieved_evidences\", [])\n",
        "            if use_retrieved\n",
        "            else []\n",
        "        )\n",
        "        test_predictions_dict[claim_id] = {\n",
        "            \"claim_text\": test_claims[claim_id][\"claim_text\"],\n",
        "            \"claim_label\": label,\n",
        "            \"evidences\": evidence_ids,\n",
        "        }\n",
        "\n",
        "    return dev_predictions, test_predictions_dict, model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using the basic TF-IDF retriever from Part 2\n",
            "Retrieving evidence for claims...\n",
            "Processing training claims...\n",
            "Processing development claims...\n",
            "Processing test claims...\n",
            "Building vocabulary...\n",
            "Vocabulary size: 20000\n",
            "\n",
            "Training LSTM classifier...\n",
            "Epoch 1/8, Train Loss: 1.3147, Train Acc: 39.91%, Valid Loss: 1.2430, Valid Acc: 46.34%\n",
            "Epoch 2/8, Train Loss: 1.2500, Train Acc: 41.45%, Valid Loss: 1.2408, Valid Acc: 46.34%\n",
            "Epoch 3/8, Train Loss: 1.2410, Train Acc: 42.90%, Valid Loss: 1.2445, Valid Acc: 46.34%\n",
            "Epoch 4/8, Train Loss: 1.2148, Train Acc: 43.08%, Valid Loss: 1.2610, Valid Acc: 43.90%\n",
            "Epoch 5/8, Train Loss: 1.1721, Train Acc: 46.52%, Valid Loss: 1.3090, Valid Acc: 38.21%\n",
            "Epoch 6/8, Train Loss: 1.1225, Train Acc: 49.05%, Valid Loss: 1.3217, Valid Acc: 34.15%\n",
            "Epoch 7/8, Train Loss: 1.0581, Train Acc: 53.48%, Valid Loss: 1.3722, Valid Acc: 34.96%\n",
            "Epoch 8/8, Train Loss: 0.9817, Train Acc: 57.65%, Valid Loss: 1.4297, Valid Acc: 29.27%\n",
            "\n",
            "Evaluating on development set...\n",
            "Evaluation Accuracy: 37.01%\n",
            "\n",
            "Predicting on test set...\n"
          ]
        }
      ],
      "source": [
        "# Get predictions using the TF-IDF retriever from Part 2\n",
        "# Make sure to run this after you have trained the retriever in Part 2\n",
        "\n",
        "# First check if we have a retriever from previous cells\n",
        "if 'retriever_basic' in globals():\n",
        "    retriever = retriever_basic\n",
        "    print(\"Using the basic TF-IDF retriever from Part 2\")\n",
        "else:\n",
        "    print(\"Retriever not found, creating a new TF-IDF retriever...\")\n",
        "    # Create and train a basic retriever\n",
        "    retriever = TfidfEvidenceRetriever(\n",
        "        max_features=10000,\n",
        "        ngram_range=(1, 2),\n",
        "        top_k=6\n",
        "    )\n",
        "    retriever.fit(evidence)\n",
        "\n",
        "# Run the claim classification pipeline\n",
        "dev_predictions, test_predictions, claim_classifier = run_claim_classification(\n",
        "    train_claims=train_claims,  # Only use training data for training\n",
        "    dev_claims=dev_claims,      # Use dev only for evaluation\n",
        "    test_claims=test_claims,\n",
        "    evidence=evidence,\n",
        "    retriever=retriever\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved development predictions to ./data\\dev-claims-predictions.json\n",
            "Saved test predictions to ./data\\test-claims-predictions.json\n"
          ]
        }
      ],
      "source": [
        "# Save predictions to files\n",
        "def save_predictions(dev_predictions, test_predictions):\n",
        "    \"\"\"\n",
        "    Save predictions to JSON files.\n",
        "    \"\"\"\n",
        "    # Save development predictions\n",
        "    with open(DEV_PREDICTIONS_PATH, 'w') as f:\n",
        "        json.dump(dev_predictions, f, indent=2)\n",
        "    print(f\"Saved development predictions to {DEV_PREDICTIONS_PATH}\")\n",
        "    \n",
        "    # Save test predictions\n",
        "    with open(TEST_PREDICTIONS_PATH, 'w') as f:\n",
        "        json.dump(test_predictions, f, indent=2)\n",
        "    print(f\"Saved test predictions to {TEST_PREDICTIONS_PATH}\")\n",
        "\n",
        "# Save predictions\n",
        "save_predictions(dev_predictions, test_predictions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mefSOe8eTmGP"
      },
      "source": [
        "## Object Oriented Programming codes here\n",
        "\n",
        "*You can use multiple code snippets. Just add more if needed*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
